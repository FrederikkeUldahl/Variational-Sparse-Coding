{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the pickle data and setting up the data to be passed to the modle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Images   moa\n",
      "0  [[[tensor(784), tensor(3280), tensor(1072)], [...  DMSO\n",
      "1  [[[tensor(704), tensor(2656), tensor(992)], [t...  DMSO\n",
      "2  [[[tensor(2144), tensor(6320), tensor(3072)], ...  DMSO\n",
      "3  [[[tensor(560), tensor(896), tensor(1520)], [t...  DMSO\n",
      "4  [[[tensor(832), tensor(4400), tensor(960)], [t...  DMSO\n"
     ]
    }
   ],
   "source": [
    "#importing data from pickle file\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "os.chdir('..\\..\\src\\models')\n",
    "from conv_vae import ConvVAE\n",
    "from conv_vae import ConvolutionalVariationalAutoEncoder\n",
    "from conv_vsc import ConvVSC\n",
    "from conv_vsc import ConvolutionalVariationalSparseCoding\n",
    "os.chdir('..\\..\\src')\n",
    "from loading_our_data import BBBC\n",
    "os.chdir('..\\data')\n",
    "\n",
    "#chose pickle subset\n",
    "#file_name = \"data_100000_images.pkl\"\n",
    "#file_name = \"data_10000_images.pkl\"\n",
    "file_name = \"data_1000_images.pkl\"\n",
    "data = open (file_name, \"rb\")\n",
    "data = pickle.load(data)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 26\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x0000021FE9C0B6D0>\n",
      "<class 'loading_our_data.BBBC'>\n",
      "in getitem\n",
      "<class 'tuple'>\n",
      "in getitem\n",
      "<class 'torch.Tensor'>\n",
      "in getitem\n",
      "<class 'str'>\n",
      "\n",
      "\n",
      "801\n",
      "in getitem\n",
      "2\n",
      "in getitem\n",
      "13872\n",
      "\n",
      "\n",
      "in getitem\n",
      "torch.FloatTensor\n",
      "in getitem\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "#Creating the data object\n",
    "dset_train = BBBC(data, \"train\")\n",
    "dset_test = BBBC(data, \"test\")\n",
    "\n",
    "batch_size = 32\n",
    "width = 68\n",
    "height = 68\n",
    "channels = 3\n",
    "cuda = True\n",
    "\n",
    "#check if we need this for somthing form src.utils\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "\n",
    "train_loader = DataLoader(dset_train,batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = DataLoader(dset_test,batch_size=batch_size, shuffle=True, **kwargs)\n",
    "print(f\"Length {len(train_loader)}\")\n",
    "print(train_loader)\n",
    "\n",
    "#images, labels = next(iter(train_loader))\n",
    "#print(images)\n",
    "\n",
    "print(type(dset_train))\n",
    "print(type(dset_train[0]))    #tuple\n",
    "print(type(dset_train[0][0])) #image\n",
    "print(type(dset_train[0][1])) #label\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(len(dset_train))        #size of dataset\n",
    "print(len(dset_train[0]))     #elements in tuple\n",
    "print(len(dset_train[0][0]))  #length of image\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(dset_train[0][0].type())    #type of image\n",
    "print(dset_train[0][0][0].type()) #type of one pixel in image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a few examples\n",
    "f, axarr = plt.subplots(3, 10, figsize=(16, 4))\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "print(\"next itter done\")\n",
    "\n",
    "# Load a batch of images into memory\n",
    "for i, ax in enumerate(axarr.flat):\n",
    "    img = images[i]/images[i].max()\n",
    "    ax.imshow(img.view(68, 68,3))\n",
    "    ax.axis('off')\n",
    "        \n",
    "plt.suptitle('Cells!')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up model parameters\n",
    "model_params = {\n",
    "    'dataset': 'BBBC',\n",
    "    'width': width,\n",
    "    'height': height,\n",
    "    'channels': channels,\n",
    "    'kernel_szs': '32,68,68',\n",
    "    'hidden_sz': 256,\n",
    "    'latent_sz': 200,\n",
    "    'learning_rate': 1e-3,\n",
    "    'alpha': 1e-4,\n",
    "    'device': 'cuda',\n",
    "    'log_interval': 5000,\n",
    "    'normalize': False,\n",
    "    'flatten': False\n",
    "}\n",
    "\n",
    "convvsc = ConvolutionalVariationalSparseCoding(**model_params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b0fd4633de05edccea65918a8b972faac23e93e000e566af4ebc5a9acb714a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
